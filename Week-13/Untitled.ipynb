{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic packages\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# keras functions\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for a mini version of VGGNet (Simonyan and Zisserman, 2015)\n",
    "class MiniVGGNet:\n",
    "    def build(height, width, depth, classes):\n",
    "        # create the model and name it MiniVGGNet\n",
    "        model = Sequential(name = 'MiniVGGNet')\n",
    "                \n",
    "        # convolutional layer with 32 3x3 feature maps\n",
    "        model.add(Conv2D(32, (3, 3), padding = 'same', input_shape = (height, width, depth)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        # convolutional layer with 32 3x3 feature maps\n",
    "        model.add(Conv2D(32, (3, 3), padding = 'same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        # 2x2 max pooling layer with stride 2x2\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # convolutional layer with 64 3x3 feature maps\n",
    "        model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        # convolutional layer with 64 3x3 feature maps\n",
    "        model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        # 2x2 max pooling layer with stride 2x2\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # flatten the activations from a square to a vector\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        # fully-connected layer\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        # fully-connected layer with softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        # return the model\n",
    "        return model\n",
    "    \n",
    "class MiniGoogLeNet:\n",
    "    def convolution_module(x, K, kX, kY, stride, channelsDim, padding=\"same\"):\n",
    "        # create a CONV -> BN -> RELU sequence\n",
    "        x = Conv2D(K, (kX, kY), strides = stride, padding = padding)(x)\n",
    "        x = BatchNormalization(axis = channelsDim)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        # return the output\n",
    "        return x\n",
    "    \n",
    "    def inception_module(x, numberOf1x1Kernels, numberOf3x3Kernels, channelsDim):\n",
    "        # define two \"parallel\" convolutions of size 1x1 and 3x3 concatenated across the channels dimension\n",
    "        convolution_1x1 = MiniGoogLeNet.convolution_module(x, numberOf1x1Kernels, 1, 1, (1, 1), channelsDim)\n",
    "        convolution_3x3 = MiniGoogLeNet.convolution_module(x, numberOf3x3Kernels, 3, 3, (1, 1), channelsDim)\n",
    "        x = concatenate([convolution_1x1, convolution_3x3], axis = channelsDim)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def downsample_module(x, K, channelsDim):\n",
    "        # define a CONV and POOL and then concatenate across the channels dimension\n",
    "        convolution_3x3 = MiniGoogLeNet.convolution_module(x, K, 3, 3, (2, 2), channelsDim, padding = 'valid')\n",
    "        pool = MaxPooling2D((3, 3), strides = (2, 2))(x)\n",
    "        x = concatenate([convolution_3x3, pool], axis = channelsDim)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def build(width, height, depth, classes):\n",
    "        inputShape = (height, width, depth)\n",
    "        channelsDim = -1\n",
    "        \n",
    "        if backend.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            channelsDim = 1\n",
    "        \n",
    "        # define the model input and first CONV module\n",
    "        inputs = Input(shape = inputShape)\n",
    "        x = MiniGoogLeNet.convolution_module(inputs, 96, 3, 3, (1, 1), channelsDim)\n",
    "        \n",
    "        # two inception modules followed by a downsample module\n",
    "        x = MiniGoogLeNet.inception_module(x, 32, 32, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 32, 48, channelsDim)\n",
    "        x = MiniGoogLeNet.downsample_module(x, 80, channelsDim)\n",
    "        \n",
    "        # four inception modules followed by a downsample module\n",
    "        x = MiniGoogLeNet.inception_module(x, 112, 48, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 96, 64, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 80, 80, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 48, 96, channelsDim)\n",
    "        x = MiniGoogLeNet.downsample_module(x, 96, channelsDim)\n",
    "        \n",
    "        # two inception modules followed by global POOL and dropout\n",
    "        x = MiniGoogLeNet.inception_module(x, 176, 160, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 176, 160, channelsDim)\n",
    "        x = AveragePooling2D((7, 7))(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        \n",
    "        # softmax classifier\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes)(x)\n",
    "        x = Activation('softmax')(x)\n",
    "        \n",
    "        # create a model\n",
    "        model = Model(inputs, x, name='MiniGoogLeNet')\n",
    "        \n",
    "        # return the model\n",
    "        return model\n",
    "    \n",
    "class ResNet:\n",
    "    def residual_module(data, K, stride, channelsDim, reduce = False, reg = 0.0001, bnEpsilon = 0.00002, bnMomentum = 0.9):\n",
    "        shortcut = data\n",
    "        \n",
    "        # 1x1 CONVs\n",
    "        bn1 = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(data)\n",
    "        act1 = Activation('relu')(bn1)\n",
    "        conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias = False, kernel_regularizer = l2(reg))(act1)\n",
    "        \n",
    "        # 3x3 CONVs\n",
    "        bn2 = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(conv1)\n",
    "        act2 = Activation('relu')(bn2)\n",
    "        conv2 = Conv2D(int(K * 0.25), (3, 3), strides = stride, padding = 'same', use_bias = False, kernel_regularizer = l2(reg))(act2)\n",
    "        \n",
    "        # 1x1 CONVs\n",
    "        bn3 = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(conv2)\n",
    "        act3 = Activation('relu')(bn3)\n",
    "        conv3 = Conv2D(K, (1, 1), use_bias = False, kernel_regularizer = l2(reg))(act3)\n",
    "        \n",
    "        # if we reduce the spatial size, apply a CONV layer to the shortcut\n",
    "        if reduce:\n",
    "            shortcut = Conv2D(K, (1, 1), strides = stride, use_bias = False, kernel_regularizer = l2(reg))(act1)\n",
    "            \n",
    "        # add the shortcut and the final CONV\n",
    "        x = add([conv3, shortcut])\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def build(width, height, depth, classes, stages, filters, reg = 0.0001, bnEpsilon = 0.00002, bnMomentum = 0.9, dataset='cifar'):\n",
    "        inputShape = (height, width, depth)\n",
    "        channelsDim = -1\n",
    "        \n",
    "        if backend.image_data_format() == 'channels_first':\n",
    "            inputShape = (depth, height, width)\n",
    "            channelsDim = 1\n",
    "            \n",
    "        # set the input and apply BN\n",
    "        inputs = Input(shape = inputShape)\n",
    "        x = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(inputs)\n",
    "        \n",
    "        if dataset == 'cifar':\n",
    "            # apply a single CONV layer\n",
    "            x = Conv2D(filters[0], (3, 3), use_bias = False, padding = 'same',\n",
    "                       kernel_regularizer = l2(reg))(x)\n",
    "        \n",
    "        # loop over the number of stages\n",
    "        for counter in range(0, len(stages)):\n",
    "            # initialize the stride\n",
    "            if counter == 0:\n",
    "                stride = (1, 1)\n",
    "            else:\n",
    "                stride = (2, 2)\n",
    "                    \n",
    "            # apply a residual module to reduce the spatial dimension of the image volume\n",
    "            x = ResNet.residual_module(x, filters[counter + 1], stride, channelsDim, reduce = True, bnEpsilon = bnEpsilon, bnMomentum = bnMomentum)\n",
    "            \n",
    "            # loop over the number of layers in the current stage\n",
    "            for j in range(0, stages[counter] - 1):\n",
    "                # apply a residual module\n",
    "                x = ResNet.residual_module(x, filters[counter + 1], (1, 1), channelsDim, bnEpsilon = bnEpsilon, bnMomentum = bnMomentum)\n",
    "                    \n",
    "        # apply BN -> ACT -> POOL\n",
    "        x = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = AveragePooling2D((8, 8))(x)\n",
    "        \n",
    "        # softmax classifier\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, kernel_regularizer = l2(reg))(x)\n",
    "        x = Activation('softmax')(x)\n",
    "        \n",
    "        # create the model\n",
    "        model = Model(inputs, x, name = 'ResNet')\n",
    "        \n",
    "        # return the model\n",
    "        return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
