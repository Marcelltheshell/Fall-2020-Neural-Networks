{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic packages\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import progressbar\n",
    "import random\n",
    "from imutils import paths\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# keras functions\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create a class for a mini version of VGGNet (Simonyan and Zisserman, 2015)\n",
    "class MiniVGGNet:\n",
    "    def build(height, width, depth, classes):\n",
    "        # create the model and name it MiniVGGNet\n",
    "        model = Sequential(name = 'MiniVGGNet')\n",
    "                \n",
    "        # convolutional layer with 32 3x3 feature maps\n",
    "        model.add(Conv2D(32, (3, 3), padding = 'same', input_shape = (height, width, depth)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        # convolutional layer with 32 3x3 feature maps\n",
    "        model.add(Conv2D(32, (3, 3), padding = 'same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        # 2x2 max pooling layer with stride 2x2\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # convolutional layer with 64 3x3 feature maps\n",
    "        model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        # convolutional layer with 64 3x3 feature maps\n",
    "        model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        # 2x2 max pooling layer with stride 2x2\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # flatten the activations from a square to a vector\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        # fully-connected layer\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        # fully-connected layer with softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        # return the model\n",
    "        return model\n",
    "    \n",
    "class MiniGoogLeNet:\n",
    "    def convolution_module(x, K, kX, kY, stride, channelsDim, padding=\"same\"):\n",
    "        # create a CONV -> BN -> RELU sequence\n",
    "        x = Conv2D(K, (kX, kY), strides = stride, padding = padding)(x)\n",
    "        x = BatchNormalization(axis = channelsDim)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        # return the output\n",
    "        return x\n",
    "    \n",
    "    def inception_module(x, numberOf1x1Kernels, numberOf3x3Kernels, channelsDim):\n",
    "        # define two \"parallel\" convolutions of size 1x1 and 3x3 concatenated across the channels dimension\n",
    "        convolution_1x1 = MiniGoogLeNet.convolution_module(x, numberOf1x1Kernels, 1, 1, (1, 1), channelsDim)\n",
    "        convolution_3x3 = MiniGoogLeNet.convolution_module(x, numberOf3x3Kernels, 3, 3, (1, 1), channelsDim)\n",
    "        x = concatenate([convolution_1x1, convolution_3x3], axis = channelsDim)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def downsample_module(x, K, channelsDim):\n",
    "        # define a CONV and POOL and then concatenate across the channels dimension\n",
    "        convolution_3x3 = MiniGoogLeNet.convolution_module(x, K, 3, 3, (2, 2), channelsDim, padding = 'valid')\n",
    "        pool = MaxPooling2D((3, 3), strides = (2, 2))(x)\n",
    "        x = concatenate([convolution_3x3, pool], axis = channelsDim)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def build(width, height, depth, classes):\n",
    "        inputShape = (height, width, depth)\n",
    "        channelsDim = -1\n",
    "        \n",
    "        if backend.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            channelsDim = 1\n",
    "        \n",
    "        # define the model input and first CONV module\n",
    "        inputs = Input(shape = inputShape)\n",
    "        x = MiniGoogLeNet.convolution_module(inputs, 96, 3, 3, (1, 1), channelsDim)\n",
    "        \n",
    "        # two inception modules followed by a downsample module\n",
    "        x = MiniGoogLeNet.inception_module(x, 32, 32, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 32, 48, channelsDim)\n",
    "        x = MiniGoogLeNet.downsample_module(x, 80, channelsDim)\n",
    "        \n",
    "        # four inception modules followed by a downsample module\n",
    "        x = MiniGoogLeNet.inception_module(x, 112, 48, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 96, 64, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 80, 80, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 48, 96, channelsDim)\n",
    "        x = MiniGoogLeNet.downsample_module(x, 96, channelsDim)\n",
    "        \n",
    "        # two inception modules followed by global POOL and dropout\n",
    "        x = MiniGoogLeNet.inception_module(x, 176, 160, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 176, 160, channelsDim)\n",
    "        x = AveragePooling2D((7, 7))(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        \n",
    "        # softmax classifier\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes)(x)\n",
    "        x = Activation('softmax')(x)\n",
    "        \n",
    "        # create a model\n",
    "        model = Model(inputs, x, name='MiniGoogLeNet')\n",
    "        \n",
    "        # return the model\n",
    "        return model\n",
    "    \n",
    "class ResNet:\n",
    "    def residual_module(data, K, stride, channelsDim, reduce = False, reg = 0.0001, bnEpsilon = 0.00002, bnMomentum = 0.9):\n",
    "        shortcut = data\n",
    "        \n",
    "        # 1x1 CONVs\n",
    "        bn1 = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(data)\n",
    "        act1 = Activation('relu')(bn1)\n",
    "        conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias = False, kernel_regularizer = l2(reg))(act1)\n",
    "        \n",
    "        # 3x3 CONVs\n",
    "        bn2 = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(conv1)\n",
    "        act2 = Activation('relu')(bn2)\n",
    "        conv2 = Conv2D(int(K * 0.25), (3, 3), strides = stride, padding = 'same', use_bias = False, kernel_regularizer = l2(reg))(act2)\n",
    "        \n",
    "        # 1x1 CONVs\n",
    "        bn3 = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(conv2)\n",
    "        act3 = Activation('relu')(bn3)\n",
    "        conv3 = Conv2D(K, (1, 1), use_bias = False, kernel_regularizer = l2(reg))(act3)\n",
    "        \n",
    "        # if we reduce the spatial size, apply a CONV layer to the shortcut\n",
    "        if reduce:\n",
    "            shortcut = Conv2D(K, (1, 1), strides = stride, use_bias = False, kernel_regularizer = l2(reg))(act1)\n",
    "            \n",
    "        # add the shortcut and the final CONV\n",
    "        x = add([conv3, shortcut])\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def build(width, height, depth, classes, stages, filters, reg = 0.0001, bnEpsilon = 0.00002, bnMomentum = 0.9, dataset='cifar'):\n",
    "        inputShape = (height, width, depth)\n",
    "        channelsDim = -1\n",
    "        \n",
    "        if backend.image_data_format() == 'channels_first':\n",
    "            inputShape = (depth, height, width)\n",
    "            channelsDim = 1\n",
    "            \n",
    "        # set the input and apply BN\n",
    "        inputs = Input(shape = inputShape)\n",
    "        x = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(inputs)\n",
    "        \n",
    "        if dataset == 'cifar':\n",
    "            # apply a single CONV layer\n",
    "            x = Conv2D(filters[0], (3, 3), use_bias = False, padding = 'same',\n",
    "                       kernel_regularizer = l2(reg))(x)\n",
    "        \n",
    "        # loop over the number of stages\n",
    "        for counter in range(0, len(stages)):\n",
    "            # initialize the stride\n",
    "            if counter == 0:\n",
    "                stride = (1, 1)\n",
    "            else:\n",
    "                stride = (2, 2)\n",
    "                    \n",
    "            # apply a residual module to reduce the spatial dimension of the image volume\n",
    "            x = ResNet.residual_module(x, filters[counter + 1], stride, channelsDim, reduce = True, bnEpsilon = bnEpsilon, bnMomentum = bnMomentum)\n",
    "            \n",
    "            # loop over the number of layers in the current stage\n",
    "            for j in range(0, stages[counter] - 1):\n",
    "                # apply a residual module\n",
    "                x = ResNet.residual_module(x, filters[counter + 1], (1, 1), channelsDim, bnEpsilon = bnEpsilon, bnMomentum = bnMomentum)\n",
    "                    \n",
    "        # apply BN -> ACT -> POOL\n",
    "        x = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = AveragePooling2D((8, 8))(x)\n",
    "        \n",
    "        # softmax classifier\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, kernel_regularizer = l2(reg))(x)\n",
    "        x = Activation('softmax')(x)\n",
    "        \n",
    "        # create the model\n",
    "        model = Model(inputs, x, name = 'ResNet')\n",
    "        \n",
    "        # return the model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5\n",
    "\n",
    "If we want to work with huge pre-trained neural nets like VGG19 or other deep CNNs, storing them takes far more space than our RAM is likely to support, so we need to store them on HDD/SDDs in an efficient way. Keras's model format is pretty large, but HDF5 is a good data format for this, but we need some code to be able to interface with this format, which we write below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDF5DataWriter:\n",
    "    def __init__(self, dims, outputPath, dataKey = 'images', bufferSize = 1000):\n",
    "        # check if outputpath exists\n",
    "        if os.path.exists(outputPath):\n",
    "            raise ValueError('The supplied `outputPath` already exists and cannot be overwritten. Delete '\n",
    "                            ' the file manually before continuing.', outputPath)\n",
    "            \n",
    "        # open the HDF5 database for writing and create two datasets: one to store the images/features and\n",
    "        # one to store the labels\n",
    "        self.db = h5py.File(outputPath, 'w')\n",
    "        self.data = self.db.create_dataset(dataKey, dim, dtype = 'float')\n",
    "        self.labels = self.db.create_dataset('labels', (dims[0],), dtype = 'float')\n",
    "        \n",
    "        # store the buffer size and initialize the buffer and index\n",
    "        self.bufferSize = bufferSize\n",
    "        self.buffer = {'data': [], 'labels': []}\n",
    "        self.index = 0\n",
    "        \n",
    "    def add(self, rows, labels):\n",
    "        # add the rows and labels to the buffer\n",
    "        self.buffer['data'].extend(rows)\n",
    "        self.buffer['labels'].extend(labels)\n",
    "        \n",
    "        # check if the buffer needs to be flushed to disk\n",
    "        if len(self.buffer['data']) >= self.bufferSize:\n",
    "            self.flush()\n",
    "            \n",
    "    def flush(self):\n",
    "        # write the buffer to disk and reset buffer\n",
    "        i = self.index + len(self.buffer['data'])\n",
    "        self.data[self.index:i] = self.buffer['data']\n",
    "        self.labels[self.index:i] = self.buffer['labels']\n",
    "        \n",
    "        self.index = i\n",
    "        self.buffer = {'data': [], 'labels': []}\n",
    "        \n",
    "    def storeClassLabels(self, classLabels):\n",
    "        # create a dataset to store class label names, then store them\n",
    "        dt = h5py.special_dtype(vlen = unicode)\n",
    "        labelSet = self.db.create_dataset('label_names', (len(classLabels),), dtype = dt)\n",
    "        labelSet[:] = classLabels\n",
    "        \n",
    "    def close(self):\n",
    "        # flush entries to disk if needed\n",
    "        if len(self.buffer['data']) > 0:\n",
    "            self.flush()\n",
    "            \n",
    "        # close the dataset\n",
    "        self.db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "Let's write some code to extract features from an arbitrary image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 32\n",
    "dataset = '../datasets/animals/images'\n",
    "output = '../datasets/animals/hdf5/features.hdf5'\n",
    "bufferSize = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading images...')\n",
    "imagePaths = list(paths.list_images(dataset))\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# extract class labels from the image paths and encode the labels (assumes the\n",
    "# file paths are in the form 'dataset_name/{class_label}/example.jpg')\n",
    "labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "\n",
    "# load the pretrained VGG16 net on the imagenet dataset but without the final\n",
    "# fully connected layers (include_top is False), so we get features after\n",
    "# propagating images through the last pooling later\n",
    "print('Loading network...')\n",
    "model = VGG16(weights = 'imagenet', include_top = False)\n",
    "\n",
    "# initialize the HDF5 dataset writer and store class label names in a dataset\n",
    "dataset = HDF5DatasetWriter((len(imagePaths), 512 * 7 * 7), output,\n",
    "                            dataKey = 'features', bufferSize)\n",
    "\n",
    "dataset.storeClassLabels(le.classes_)\n",
    "\n",
    "# initialize the progress bar\n",
    "widgets = ['Extracting features: ', progressbar.Percentage(), ' ', progressbar.Bar(),\n",
    "          ' ', progressbar.ETA()]\n",
    "\n",
    "pbar = progressbar.ProgressBar(maxval = len(imagePaths), widgets = widgets).start()\n",
    "\n",
    "# loop over the images in batches\n",
    "for i in np.arange(0, len(imagePaths), bs):\n",
    "    # extract the batch of images/labels and initialize the list of images that will\n",
    "    # be passed through the net for feature extration\n",
    "    batchPaths = imagePaths[i:i + bs]\n",
    "    batchLabels = labels[i:i + bs]\n",
    "    batchImages = []\n",
    "    \n",
    "    # loop over the images/labels in the current batch\n",
    "    for (j, imagePath) in enumerate(batchPaths):\n",
    "        # load the input image and resize it to 224x224 pixels\n",
    "        image = load_img(imagePath, target_size = (224, 224))\n",
    "        image = img_to_array(image)\n",
    "        \n",
    "        # preprocess by expanding dimensions and subtracting mean RGB pixel\n",
    "        # intensity from ImageNet\n",
    "        image = np.expand_dims(image, axis = 0)\n",
    "        image = imagenet_utils.preprocess_input(image)\n",
    "        \n",
    "        # add the images to the batch\n",
    "        batchImages.append(image)\n",
    "        \n",
    "    # pass images through net and use outputs as features\n",
    "    batchImages = np.vstack(batchImages)\n",
    "    features = model.predict(batchImages, batch_size = batchSize)\n",
    "    \n",
    "    # flattened each image to a feature vector of the MaxPooling2D outputs\n",
    "    features = features.reshape((features.shape[0], 512 * 7 * 7))\n",
    "    \n",
    "    # add the featuers and labels to the HDF5 dataset\n",
    "    dataset.add(features, batchLabels)\n",
    "    pbar.update(i)\n",
    "    \n",
    "    # close the dataset\n",
    "    dataset.close()\n",
    "    pbar.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
