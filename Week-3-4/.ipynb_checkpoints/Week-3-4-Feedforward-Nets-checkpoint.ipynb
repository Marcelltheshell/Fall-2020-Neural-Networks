{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Networks\n",
    "\n",
    "This week, we will introduce (artificial) neural networks, which are machine learning methods that draw inspiration from biological nervous systems where huge numbers of interconnected neurons (nerve cells) send electricalchemical signals, frequently in response to external stimuli, to one another throughout the body and within the brain.\n",
    "\n",
    "Neural networks excel at machine learning tasks when large amounts of data is available (thousands of datapoints). We will, for now, focus on the applications of neural networks to classification and regression problems.\n",
    "\n",
    "This week's notes will be mostly dedicated sharing my code with you because we will primarily be studying from <a href=\"http://neuralnetworksanddeeplearning.com/\">*Neural Networks and Deep Learning*</a> by Michael Nielsen. This <a href=\"https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi\">playlist of YouTube videos</a> is based on Nielsen's book and is pretty amazing for explaining this content as well. I cannot recommend it enough!\n",
    "\n",
    "<a href=\"https://github.com/mnielsen/neural-networks-and-deep-learning\">Nielsen's code</a> is written in Python 2.7, so I would not recommend using his code, but Michal Daniel Dobrzanski provides <a href=\"https://github.com/MichalDanielDobrzanski/DeepLearningPython35\">updated code</a> in Python 3.5.\n",
    "\n",
    "## Perceptrons\n",
    "\n",
    "Refer to my PDF notes for details, but we will write some code for Perceptrons below. First, we import numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, N, alpha = 0.1):\n",
    "        # initialize the weights randomly and learning rate\n",
    "        self.W = np.random.randn(N + 1)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def fit(self, X, y, epochs = 10):\n",
    "        # insert a column of 1s at the end of X\n",
    "        X = np.hstack((X, np.ones([X.shape[0], 1])))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # do the dot product between w and x\n",
    "            for (x, target) in zip(X,y):\n",
    "                \n",
    "                dotProduct = np.dot(x, self.W)\n",
    "                \n",
    "                if dotProduct < 0 and target == 1:\n",
    "                    self.W += self.alpha*x\n",
    "                \n",
    "                if dotProduct >= 0 and target == 0:\n",
    "                    self.W -= self.alpha*x\n",
    "                    \n",
    "    def predict(self, X):\n",
    "        X = np.hstack((X, np.ones([X.shape[0], 1])))\n",
    "        \n",
    "        predictedY = np.zeros([X.shape[0], 1])\n",
    "        \n",
    "        for counter in range(X.shape[0]):\n",
    "            dotProduct = np.dot(X[counter,], self.W)\n",
    "            \n",
    "            if dotProduct < 0:\n",
    "                predictedY[counter] = 0\n",
    "            \n",
    "            else:\n",
    "                predictedY[counter] = 1\n",
    "                \n",
    "        return predictedY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: OR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [1]])\n",
    "\n",
    "model = Perceptron(X.shape[1], alpha=0.1)\n",
    "model.fit(X, y, epochs=100)\n",
    "yPredicted = model.predict(X)\n",
    "\n",
    "print(classification_report(y, yPredicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it works perfectly at approximating the OR function since the data is linearly separable.\n",
    "\n",
    "### Example: Random Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78        27\n",
      "           1       0.74      0.74      0.74        23\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.76      0.76      0.76        50\n",
      "weighted avg       0.76      0.76      0.76        50\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cc50e9eec8>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of points to generate\n",
    "numberOfPoints = 100\n",
    "\n",
    "# generate points from class 0\n",
    "mean1 = np.array([-1, -1])\n",
    "covariance1 = np.array([[5, 0], [0, 5]])\n",
    "X1 = np.random.multivariate_normal(mean1, covariance1, numberOfPoints)\n",
    "\n",
    "# generate points from class 1\n",
    "mean2 = np.array([3, 3])\n",
    "covariance2 = np.array([[5, 3], [3, 5]])\n",
    "X2 = np.random.multivariate_normal(mean2, covariance2, numberOfPoints)\n",
    "\n",
    "# stack the points\n",
    "X = np.vstack((X1, X2))\n",
    "\n",
    "# create a vector of the labels\n",
    "y = np.hstack((numberOfPoints * [0], numberOfPoints * [1]))\n",
    "\n",
    "# train test split\n",
    "(trainX, testX, trainY, testY) = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
    "\n",
    "# instantiate a model\n",
    "model = Perceptron(2)\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(trainX, trainY, epochs = 1000)\n",
    "predictedY = model.predict(testX)\n",
    "\n",
    "print(classification_report(testY, predictedY))\n",
    "\n",
    "# plot the training set\n",
    "plt.scatter(trainX[:,0], trainX[:,1], c = trainY, marker = '.')\n",
    "\n",
    "parameters = model.W\n",
    "\n",
    "xModel = np.linspace(-10, 10, 100)\n",
    "yModel = -parameters[0]/parameters[1]*xModel - parameters[2]/parameters[0]\n",
    "lineFormula = '{:.3f}x_1+{:.3f}x_2+{:.3f}=0'.format(parameters[0], parameters[1], parameters[2])\n",
    "plt.plot(xModel, yModel, 'g', label = lineFormula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the Perceptron algorithm can achieve decent accuracy on test accuracy at 78%, but the method clearly has its limitations since it can only create a linear decision boundary. It has performed as well as it can under this restriction, but it is typically a poor assumption for practical binary classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Feedforward Neural Networks\n",
    "\n",
    "Let's take it a step forward and write some code for neural networks (to be continued!)\n",
    "\n",
    "There are three main bits of code we need to make neural nets work. Assume that we have a training dataset $X$.\n",
    "\n",
    "1. **Forward pass**: feeds a datapoint into a neural network and processes it by computing the outputs of each layer of artificial neurons until we reach the output layer and compute the loss\n",
    "\n",
    "2. **Stochastic gradient descent (SGD)**: after feeding in some data and computing the loss, we need to adjust the weights in such a way to reduce the loss function (in the opposite direction of the gradient)\n",
    "\n",
    "3. **Backpropagation (Backprop)**: to find gradient formulas, this will use the chain rule in a systematic way to find the gradient of the loss function\n",
    "\n",
    "### The Forward Pass\n",
    "\n",
    "The forward pass is simple, we just follow the simple rules of the individual neurons, but we have to do it **many** times, which we can automate with matrix multiplication (see our notes from class on Sept 3).\n",
    "\n",
    "### Stochastic Gradient Descent\n",
    "\n",
    "We already know what gradient descent is, we run our model on training data, compute the loss function, find the gradient of the loss function (i.e. the derivatives of the loss function with respect to each parameter), and update our parameters in the opposite direction of the gradient by a small amount. The same general approach will be used in most neural networks.\n",
    "\n",
    "In linear models, we compute the outputs and loss function for the entire dataset (usually multiple times) per iteration of gradient descent, make a weight update based on the gradient, and repeat. At the other end of the spectrum, the Perceptron algorithm made a weight update for every single datapoint input.\n",
    "\n",
    "The typical approach in neural networks is **stochastic** gradient descent (SGD). It turns out, computing outputs for the whole dataset or only a single input before making a weight update is expensive, but doing a weight update after each datapoint would be a bad idea because outlier datapoints might have an overly strong pull on parameters. SGD takes a middle path: update weights after processing a random sample, called a **mini-batch**, of datapoints--enough points to reduce the variance of using just one for more stable convergence of parameters, but not so much that the computation is not too expensive. In this way, we process a mini-batch for outputs, compute an approximate loss function and approximate gradients, update weights, and repeat\n",
    "\n",
    "How large should our mini-batches be? Typically, using $2^n$ for something like $n=5, 6, 7, 8$ because these values tend to be ideal for the linear algebra optimization libraries we use (NumPy, TensorFlow, etc). The mini-batch size is a hyperparameter, but it generally isn't one you need to tweak. One exception is if you are using GPUs for computing: then, it's best to choose the largest power of 2 that allows a whole mini-batch to fit into GPU memory.\n",
    "\n",
    "\n",
    "### Backpropagation\n",
    "\n",
    "In the past, we approximated the gradient by computing the loss functions many times, perturbed in each dimension to compute\n",
    "\n",
    "$$\\nabla L(\\beta)\\approx\\left(\\frac{L(\\beta+he_0)-L(\\beta)}{h}, ..., \\frac{L(\\beta+he_d)-L(\\beta)}{h}\\right)$$\n",
    "\n",
    "for some small value $h$, but this meant we had to compute the loss function $d+2$ times for **each** iteration in gradient descent, which required us to compute the outputs of the model for the whole dataset many, many times. This was fine for the linear regression models we have considered, but it would be too computationally expensive to feed the whole dataset through a neural network so many times.\n",
    "\n",
    "As a result, we instead need another method to compute gradients. It turns out, we can systematically apply the chain rule to get formulas for the partial derivatives of the loss function with respect to each weight in the neural network. Backpropagation does just this.\n",
    "\n",
    "### Feedforward Neural Network Class\n",
    "\n",
    "We will write the three parts above as functions within a class for constructing feedforward neural networks.\n",
    "\n",
    "First, import some packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can write our class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetwork:\n",
    "    \n",
    "    # input a vector [a, b, c, ...] with the number of nodes in each layer\n",
    "    def __init__(self, layers, alpha = 0.1):\n",
    "        # list of weight matrices between layers\n",
    "        self.W = []\n",
    "        \n",
    "        # network architecture will be a vector of numbers of nodes for each layer\n",
    "        self.layers = layers\n",
    "        \n",
    "        # learning rate\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # initialize the weights (randomly) -- this is our initial guess for gradient descent\n",
    "        \n",
    "        # initialize the weights between layers (up to the next-to-last one) as normal random variables\n",
    "        for i in np.arange(0, len(layers) - 2):\n",
    "            self.W.append(np.random.randn(layers[i] + 1, layers[i + 1] + 1))\n",
    "            \n",
    "        # initialize weights between the last two layers (we don't want bias for the last one)\n",
    "        self.W.append(np.random.randn(layers[-2] + 1, layers[-1]))\n",
    "        \n",
    "    # define the sigmoid activation\n",
    "    def sigmoid(self, x):\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "    \n",
    "    # define the sigmoid derivative (where z is the output of a sigmoid)\n",
    "    def sigmoidDerivative(self, z):\n",
    "        return z * (1 - z)\n",
    "    \n",
    "    # fit the model\n",
    "    def fit(self, X, y, epochs = 1000):\n",
    "        # add a column of ones to the end of X\n",
    "        X = np.hstack((X, np.ones([X.shape[0],1])))\n",
    "\n",
    "        for epoch in np.arange(0,epochs):\n",
    "\n",
    "            # feed forward, backprop, and weight update\n",
    "            for (x, target) in zip(X, y):\n",
    "                # make a list of output activations from the first layer\n",
    "                # (just the original x values)\n",
    "                A = [np.atleast_2d(x)]\n",
    "                \n",
    "                # feed forward\n",
    "                for layer in np.arange(0, len(self.W)):\n",
    "                    \n",
    "                    # feed through one layer and apply sigmoid activation\n",
    "                    net = A[layer].dot(self.W[layer])\n",
    "                    out = self.sigmoid(net)\n",
    "                    \n",
    "                    # add our network output to the list of activations\n",
    "                    A.append(out)\n",
    "                    \n",
    "                # backpropagation (coming soon!)\n",
    "                error = A[-1] - target\n",
    "                \n",
    "                D = [error * self.sigmoidDerivative(A[-1])]\n",
    "                \n",
    "                # loop backwards over the layers to build up deltas\n",
    "                for layer in np.arange(len(A) - 2, 0, -1):\n",
    "                    delta = D[-1].dot(self.W[layer].T)\n",
    "                    delta = delta * self.sigmoidDerivative(A[layer])\n",
    "                    D.append(delta)\n",
    "                    \n",
    "                # reverse the deltas since we looped in reverse\n",
    "                D = D[::-1]\n",
    "                \n",
    "                # weight update\n",
    "                for layer in np.arange(0, len(self.W)):\n",
    "                    self.W[layer] -= self.alpha * A[layer].T.dot(D[layer])\n",
    "                    \n",
    "            if (epoch + 1) % 1000 == 0:\n",
    "                loss = self.computeLoss(X,y)\n",
    "                print(\"[INFO] epoch = {}, loss = {:.6f}\".format(epoch + 1, loss))\n",
    "                \n",
    "    def predict(self, X, addOnes = True):\n",
    "        # initialize data, be sure it's the right dimension\n",
    "        p = np.atleast_2d(X)\n",
    "        \n",
    "        # add a column of 1s for bias\n",
    "        if addOnes:\n",
    "            p = np.hstack((p, np.ones([X.shape[0],1])))\n",
    "        \n",
    "        # feed forward!\n",
    "        for layer in np.arange(0, len(self.W)):\n",
    "            p = self.sigmoid(np.dot(p, self.W[layer]))\n",
    "            \n",
    "        return p\n",
    "    \n",
    "    def computeLoss(self, X, y):\n",
    "        # initialize data, be sure it's the right dimension\n",
    "        y = np.atleast_2d(y)\n",
    "        \n",
    "        # feed the datapoints through the network to get predicted outputs\n",
    "        predictions = self.predict(X, addOnes = False)\n",
    "        loss = np.sum((predictions - y)**2) / 2.0\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W': [array([[ 0.55661066, -0.30102169,  0.0774323 ],\n",
       "         [ 1.62640366,  0.29493935, -0.44629322],\n",
       "         [ 0.67004021, -0.14849812,  1.03052808]]),\n",
       "  array([[ 0.23441355],\n",
       "         [ 0.31083165],\n",
       "         [-0.34832858]])],\n",
       " 'layers': [2, 2, 1],\n",
       " 'alpha': 0.1}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FeedforwardNeuralNetwork([2, 2, 1])\n",
    "vars(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] epoch = 1000, loss = 0.483990\n",
      "[INFO] epoch = 2000, loss = 0.397447\n",
      "[INFO] epoch = 3000, loss = 0.207871\n",
      "[INFO] epoch = 4000, loss = 0.071256\n",
      "[INFO] epoch = 5000, loss = 0.035409\n",
      "[INFO] epoch = 6000, loss = 0.022308\n",
      "[INFO] epoch = 7000, loss = 0.015943\n",
      "[INFO] epoch = 8000, loss = 0.012278\n",
      "[INFO] epoch = 9000, loss = 0.009926\n",
      "[INFO] epoch = 10000, loss = 0.008300\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# XOR FUNCTION -- just to be sure feed-forward works right\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "random.seed(1)\n",
    "model.fit(X,y,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0248144 ],\n",
       "       [0.93316177],\n",
       "       [0.93010569],\n",
       "       [0.08143967]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all good!\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
