{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Experiments and Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MiniGoogLeNet\n",
    "\n",
    "Note for GoogLeNet, the inception modules are not exactly sequential, so we will need to define layers a little differently as we see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "class MiniGoogLeNet:\n",
    "    def convolution_module(x, K, kX, kY, stride, channelsDim, padding=\"same\"):\n",
    "        # create a CONV -> BN -> RELU sequence\n",
    "        x = Conv2D(K, (kX, kY), strides = stride, padding = padding)(x)\n",
    "        x = BatchNormalization(axis = channelsDim)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        # return the output\n",
    "        return x\n",
    "    \n",
    "    def inception_module(x, numberOf1x1Kernels, numberOf3x3Kernels, channelsDim):\n",
    "        # define two \"parallel\" convolutions of size 1x1 and 3x3 concatenated across the channels dimension\n",
    "        convolution_1x1 = MiniGoogLeNet.convolution_module(x, numberOf1x1Kernels, 1, 1, (1, 1), channelsDim)\n",
    "        convolution_3x3 = MiniGoogLeNet.convolution_module(x, numberOf3x3Kernels, 3, 3, (1, 1), channelsDim)\n",
    "        x = concatenate([convolution_1x1, convolution_3x3], axis = channelsDim)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def downsample_module(x, K, channelsDim):\n",
    "        # define a CONV and POOL and then concatenate across the channels dimension\n",
    "        convolution_3x3 = MiniGoogLeNet.convolution_module(x, K, 3, 3, (2, 2), channelsDim, padding = 'valid')\n",
    "        pool = MaxPooling2D((3, 3), strides = (2, 2))(x)\n",
    "        x = concatenate([convolution_3x3, pool], axis = channelsDim)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def build(width, height, depth, classes):\n",
    "        inputShape = (height, width, depth)\n",
    "        channelsDim = -1\n",
    "        \n",
    "        if backend.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            channelsDim = 1\n",
    "        \n",
    "        # define the model input and first CONV module\n",
    "        inputs = Input(shape = inputShape)\n",
    "        x = MiniGoogLeNet.convolution_module(inputs, 96, 3, 3, (1, 1), channelsDim)\n",
    "        \n",
    "        # two inception modules followed by a downsample module\n",
    "        x = MiniGoogLeNet.inception_module(x, 32, 32, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 32, 48, channelsDim)\n",
    "        x = MiniGoogLeNet.downsample_module(x, 80, channelsDim)\n",
    "        \n",
    "        # four inception modules followed by a downsample module\n",
    "        x = MiniGoogLeNet.inception_module(x, 112, 48, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 96, 64, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 80, 80, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 48, 96, channelsDim)\n",
    "        x = MiniGoogLeNet.downsample_module(x, 96, channelsDim)\n",
    "        \n",
    "        # two inception modules followed by global POOL and dropout\n",
    "        x = MiniGoogLeNet.inception_module(x, 176, 160, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 176, 160, channelsDim)\n",
    "        x = AveragePooling2D((7, 7))(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        \n",
    "        # softmax classifier\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes)(x)\n",
    "        x = Activation('softmax')(x)\n",
    "        \n",
    "        # create a model\n",
    "        model = Model(inputs, x, name='MiniGoogLeNet')\n",
    "        \n",
    "        # return the model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/70\n",
      " 6016/50000 [==>...........................] - ETA: 32:42 - loss: 1.9697 - accuracy: 0.2666"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "numberOfEpochs = 70\n",
    "initialLearningRate = 0.005\n",
    "\n",
    "def polynomial_decay(epoch):\n",
    "    maxEpochs = numberOfEpochs\n",
    "    baseLearningRate = initialLearningRate\n",
    "    power = 1.0\n",
    "    \n",
    "    alpha = baseLearningRate * (1 - (epoch / float(numberOfEpochs))) ** power\n",
    "    \n",
    "    # return the learning rate\n",
    "    return alpha\n",
    "    \n",
    "# load cifar10 data\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype('float')\n",
    "testX = testX.astype('float')\n",
    "\n",
    "# use mean subtraction\n",
    "mean = np.mean(trainX, axis = 0)\n",
    "trainX -= mean\n",
    "testX -= mean\n",
    "\n",
    "# convert labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "#aug = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1,\n",
    "#                         horizontal_flip = True, fill_mode=\"nearest\")\n",
    "\n",
    "callbacks = [LearningRateScheduler(polynomial_decay)]\n",
    "\n",
    "print('[INFO] compiling model...')\n",
    "opt = SGD(lr = initialLearningRate, momentum=0.9)\n",
    "model = MiniGoogLeNet.build(width = 32, height = 32, depth = 3, classes = 10)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(trainX, trainY, validation_data = (testX, testY), batch_size = 64, epochs = numberOfEpochs,\n",
    "              callbacks = callbacks, verbose = 1)\n",
    "\n",
    "#model.fit_generator(aug.flow(trainX, trainY, batch_size=64), validation_data=(testX, testY),\n",
    "#                    steps_per_epoch=len(trainX) // 64, epochs=numberOfEpochs, callbacks = callbacks, verbose=1)\n",
    "\n",
    "# save the network to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save('output/MiniGoogLeNet_cifar10.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
